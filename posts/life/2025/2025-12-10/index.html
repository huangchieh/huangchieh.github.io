<!doctype html><html lang=zh-tw dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>機器學習勢 | 時光屋</title>
<meta name=keywords content><meta name=description content="今天有點空閒的時間， 想要看看Bingqing老師的文章， 結果發現有好多的東西， 一頭霧水。 我想有好幾個不清楚的東西， 第一個就是圖神經網絡，還沒有學會。 說到圖這種結構我就蒙了。 那第一個要解決的問題應該是圖神經網絡。 理解了之後應該就會很優雅， 有趣。 有些東西確實不簡單， 但真正掌握了應該會很有成就感吧。 要想人前優雅， 就要人後把改學的東西學了才可以。 讓AI給我寫了一個Roadmap。
Roadmap: Building a Machine Learning Potential (MLP) for Atomistic Simulations This roadmap guides you through the stages of learning required to develop a machine learning interatomic potential from scratch. It starts with fundamental concepts and progresses to advanced integration into simulation tools. Each stage lists key topics, recommended resources, and what you should be able to achieve before moving on."><meta name=author content><link rel=canonical href=https://huangchieh.github.io/posts/life/2025/2025-12-10/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://huangchieh.github.io/assets/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://huangchieh.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://huangchieh.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://huangchieh.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://huangchieh.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-tw href=https://huangchieh.github.io/posts/life/2025/2025-12-10/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:title" content="機器學習勢"><meta property="og:description" content="今天有點空閒的時間， 想要看看Bingqing老師的文章， 結果發現有好多的東西， 一頭霧水。 我想有好幾個不清楚的東西， 第一個就是圖神經網絡，還沒有學會。 說到圖這種結構我就蒙了。 那第一個要解決的問題應該是圖神經網絡。 理解了之後應該就會很優雅， 有趣。 有些東西確實不簡單， 但真正掌握了應該會很有成就感吧。 要想人前優雅， 就要人後把改學的東西學了才可以。 讓AI給我寫了一個Roadmap。
Roadmap: Building a Machine Learning Potential (MLP) for Atomistic Simulations This roadmap guides you through the stages of learning required to develop a machine learning interatomic potential from scratch. It starts with fundamental concepts and progresses to advanced integration into simulation tools. Each stage lists key topics, recommended resources, and what you should be able to achieve before moving on."><meta property="og:type" content="article"><meta property="og:url" content="https://huangchieh.github.io/posts/life/2025/2025-12-10/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-10T00:00:00+00:00"><meta property="article:modified_time" content="2025-12-10T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="機器學習勢"><meta name=twitter:description content="今天有點空閒的時間， 想要看看Bingqing老師的文章， 結果發現有好多的東西， 一頭霧水。 我想有好幾個不清楚的東西， 第一個就是圖神經網絡，還沒有學會。 說到圖這種結構我就蒙了。 那第一個要解決的問題應該是圖神經網絡。 理解了之後應該就會很優雅， 有趣。 有些東西確實不簡單， 但真正掌握了應該會很有成就感吧。 要想人前優雅， 就要人後把改學的東西學了才可以。 讓AI給我寫了一個Roadmap。
Roadmap: Building a Machine Learning Potential (MLP) for Atomistic Simulations This roadmap guides you through the stages of learning required to develop a machine learning interatomic potential from scratch. It starts with fundamental concepts and progresses to advanced integration into simulation tools. Each stage lists key topics, recommended resources, and what you should be able to achieve before moving on."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://huangchieh.github.io/posts/"},{"@type":"ListItem","position":2,"name":"機器學習勢","item":"https://huangchieh.github.io/posts/life/2025/2025-12-10/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"機器學習勢","name":"機器學習勢","description":"今天有點空閒的時間， 想要看看Bingqing老師的文章， 結果發現有好多的東西， 一頭霧水。 我想有好幾個不清楚的東西， 第一個就是圖神經網絡，還沒有學會。 說到圖這種結構我就蒙了。 那第一個要解決的問題應該是圖神經網絡。 理解了之後應該就會很優雅， 有趣。 有些東西確實不簡單， 但真正掌握了應該會很有成就感吧。 要想人前優雅， 就要人後把改學的東西學了才可以。 讓AI給我寫了一個Roadmap。\nRoadmap: Building a Machine Learning Potential (MLP) for Atomistic Simulations This roadmap guides you through the stages of learning required to develop a machine learning interatomic potential from scratch. It starts with fundamental concepts and progresses to advanced integration into simulation tools. Each stage lists key topics, recommended resources, and what you should be able to achieve before moving on.","keywords":[],"articleBody":"今天有點空閒的時間， 想要看看Bingqing老師的文章， 結果發現有好多的東西， 一頭霧水。 我想有好幾個不清楚的東西， 第一個就是圖神經網絡，還沒有學會。 說到圖這種結構我就蒙了。 那第一個要解決的問題應該是圖神經網絡。 理解了之後應該就會很優雅， 有趣。 有些東西確實不簡單， 但真正掌握了應該會很有成就感吧。 要想人前優雅， 就要人後把改學的東西學了才可以。 讓AI給我寫了一個Roadmap。\nRoadmap: Building a Machine Learning Potential (MLP) for Atomistic Simulations This roadmap guides you through the stages of learning required to develop a machine learning interatomic potential from scratch. It starts with fundamental concepts and progresses to advanced integration into simulation tools. Each stage lists key topics, recommended resources, and what you should be able to achieve before moving on.\nStage 1: Foundational Machine Learning Knowledge (Beginner) Core ML Concepts (Regression \u0026 Optimization):\nUnderstand supervised learning for regression, gradient descent, loss functions.\nGoal: Train and evaluate a simple regression model.\nResources: Andrew Ng’s ML course, “Hands-On ML with Scikit-Learn and TensorFlow”.\nNeural Networks and Backpropagation:\nLearn how feedforward neural networks work.\nGoal: Build and train a 2-3 layer neural network using PyTorch or TensorFlow.\nResources: Michael Nielsen’s book, CS231n notes, PyTorch tutorials.\nPractical ML Skills:\nLearn model evaluation, train/validation split, overfitting, and regularization.\nGoal: Train ML models on regression datasets and track performance.\nStage 2: Atomistic Simulation Basics (Beginner to Intermediate) DFT and Classical Potentials:\nLearn the difference between DFT and classical MD. Understand why MLPs are needed.\nGoal: Be able to explain the need for ML potentials.\nResources: DFT tutorials, “DFT 101”, “Understanding Molecular Simulation”.\nPotential Energy Surfaces and Forces:\nUnderstand energy landscapes and how forces relate to gradients.\nGoal: Explain how forces are computed and used in MD.\nRunning Simple MD Simulations:\nRun MD with LAMMPS, ASE, or other tools using classical potentials.\nGoal: Run a basic MD simulation and understand output.\nStage 3: Atomic Descriptors and Representations (Intermediate) Symmetry Functions (ACSF) and SOAP:\nLearn how local atomic environments are described.\nGoal: Compute descriptors for a small system (e.g., using DScribe).\nGraph Neural Networks (Optional Advanced Path):\nLearn how GNNs model atomic systems via message passing.\nGoal: Understand how graphs represent molecules and materials.\nFeature Quality:\nUnderstand what features capture relevant physics (distances, angles, etc.).\nGoal: Choose and justify a descriptor method for your own project.\nStage 4: Energy and Force Prediction with ML Models (Intermediate) Atomic Energy Decomposition:\nLearn how total energy = sum of atomic energies in MLPs.\nGoal: Implement a per-atom NN model to predict total energy.\nDifferentiation for Forces:\nUse autograd to compute forces from energy predictions.\nGoal: Implement a force calculation using automatic differentiation.\nCombined Loss Functions:\nTrain models using both energy and force loss.\nGoal: Define a custom loss and train a model with weighted energy and force terms.\nPhysical Constraints and Regularization:\nApply regularization, unit conversions, and physical sanity checks.\nStage 5: Data Generation and Preprocessing (Intermediate) Generating DFT Reference Data:\nUse DFT or ab initio MD to generate diverse atomic structures and outputs.\nGoal: Build a training dataset of structures, energies, and forces.\nNeighbor Lists and Cutoffs:\nImplement cutoff-based neighbor list generation.\nGoal: For each atom, find neighbors within a fixed radius.\nFeature Scaling and Formatting:\nNormalize descriptors and subtract per-atom reference energies.\nGoal: Prepare dataset for training.\nTools:\nUse ASE, DScribe, and other utilities to automate preprocessing.\nGoal: Have a clean training dataset ready for ML input.\nStage 6: Training and Evaluating MLPs (Advanced) Training Setup:\nChoose network architecture, optimizer, and loss terms.\nGoal: Successfully train a model on your dataset.\nHyperparameter Tuning:\nExperiment with network size, learning rate, loss weights.\nGoal: Minimize test error and avoid overfitting.\nError Evaluation:\nUse RMSE on energies and forces. Check predictions vs. DFT.\nGoal: Achieve meV-level errors if possible.\nPhysical Validation:\nRun short MD or structure relaxations using your model.\nGoal: Confirm conservation of energy, correct equilibrium structures, etc.\nActive Learning (Optional):\nExpand dataset based on failure regions.\nGoal: Iteratively improve performance.\nStage 7: Integration into Simulation Frameworks (Advanced) ASE Integration:\nWrite an ASE Calculator that calls your model.\nGoal: Use your MLP in ASE for optimization or MD.\nLAMMPS Integration:\nOptions include custom pair styles, Python callbacks, or external libraries.\nGoal: Run LAMMPS using your model (start with small test systems).\nOpenMM or Other Engines (Optional):\nUse with other tools like OpenMM for biomolecular systems.\nGoal: Connect MLP to any tool that supports custom force fields.\nFinal Tests:\nValidate energy/force agreement between standalone and simulation engine.\nGoal: Use your model in real MD runs with confidence.\nEnd Goal: Be able to train your own machine learning potential on DFT data, validate its accuracy, and run real simulations (structure optimization or MD) using it in ASE or LAMMPS.\n","wordCount":"731","inLanguage":"zh-tw","datePublished":"2025-12-10T00:00:00Z","dateModified":"2025-12-10T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://huangchieh.github.io/posts/life/2025/2025-12-10/"},"publisher":{"@type":"Organization","name":"時光屋","logo":{"@type":"ImageObject","url":"https://huangchieh.github.io/assets/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://huangchieh.github.io/ accesskey=h title="時光屋 (Alt + H)">時光屋</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">機器學習勢</h1><div class=post-meta><span title='2025-12-10 00:00:00 +0000 UTC'>2025/12/10</span></div></header><div class=post-content><p>今天有點空閒的時間， 想要看看Bingqing老師的文章， 結果發現有好多的東西， 一頭霧水。 我想有好幾個不清楚的東西， 第一個就是圖神經網絡，還沒有學會。 說到圖這種結構我就蒙了。 那第一個要解決的問題應該是圖神經網絡。 理解了之後應該就會很優雅， 有趣。 有些東西確實不簡單， 但真正掌握了應該會很有成就感吧。 要想人前優雅， 就要人後把改學的東西學了才可以。 讓AI給我寫了一個Roadmap。</p><h1 id=roadmap-building-a-machine-learning-potential-mlp-for-atomistic-simulations>Roadmap: Building a Machine Learning Potential (MLP) for Atomistic Simulations<a hidden class=anchor aria-hidden=true href=#roadmap-building-a-machine-learning-potential-mlp-for-atomistic-simulations>#</a></h1><p>This roadmap guides you through the stages of learning required to develop a machine learning interatomic potential from scratch. It starts with fundamental concepts and progresses to advanced integration into simulation tools. Each stage lists key topics, recommended resources, and what you should be able to achieve before moving on.</p><hr><h2 id=stage-1-foundational-machine-learning-knowledge-beginner>Stage 1: Foundational Machine Learning Knowledge (Beginner)<a hidden class=anchor aria-hidden=true href=#stage-1-foundational-machine-learning-knowledge-beginner>#</a></h2><ul><li><p><strong>Core ML Concepts (Regression & Optimization):</strong><br>Understand supervised learning for regression, gradient descent, loss functions.<br><em>Goal:</em> Train and evaluate a simple regression model.<br><em>Resources:</em> Andrew Ng’s ML course, “Hands-On ML with Scikit-Learn and TensorFlow”.</p></li><li><p><strong>Neural Networks and Backpropagation:</strong><br>Learn how feedforward neural networks work.<br><em>Goal:</em> Build and train a 2-3 layer neural network using PyTorch or TensorFlow.<br><em>Resources:</em> Michael Nielsen’s book, CS231n notes, PyTorch tutorials.</p></li><li><p><strong>Practical ML Skills:</strong><br>Learn model evaluation, train/validation split, overfitting, and regularization.<br><em>Goal:</em> Train ML models on regression datasets and track performance.</p></li></ul><hr><h2 id=stage-2-atomistic-simulation-basics-beginner-to-intermediate>Stage 2: Atomistic Simulation Basics (Beginner to Intermediate)<a hidden class=anchor aria-hidden=true href=#stage-2-atomistic-simulation-basics-beginner-to-intermediate>#</a></h2><ul><li><p><strong>DFT and Classical Potentials:</strong><br>Learn the difference between DFT and classical MD. Understand why MLPs are needed.<br><em>Goal:</em> Be able to explain the need for ML potentials.<br><em>Resources:</em> DFT tutorials, “DFT 101”, “Understanding Molecular Simulation”.</p></li><li><p><strong>Potential Energy Surfaces and Forces:</strong><br>Understand energy landscapes and how forces relate to gradients.<br><em>Goal:</em> Explain how forces are computed and used in MD.</p></li><li><p><strong>Running Simple MD Simulations:</strong><br>Run MD with LAMMPS, ASE, or other tools using classical potentials.<br><em>Goal:</em> Run a basic MD simulation and understand output.</p></li></ul><hr><h2 id=stage-3-atomic-descriptors-and-representations-intermediate>Stage 3: Atomic Descriptors and Representations (Intermediate)<a hidden class=anchor aria-hidden=true href=#stage-3-atomic-descriptors-and-representations-intermediate>#</a></h2><ul><li><p><strong>Symmetry Functions (ACSF) and SOAP:</strong><br>Learn how local atomic environments are described.<br><em>Goal:</em> Compute descriptors for a small system (e.g., using DScribe).</p></li><li><p><strong>Graph Neural Networks (Optional Advanced Path):</strong><br>Learn how GNNs model atomic systems via message passing.<br><em>Goal:</em> Understand how graphs represent molecules and materials.</p></li><li><p><strong>Feature Quality:</strong><br>Understand what features capture relevant physics (distances, angles, etc.).<br><em>Goal:</em> Choose and justify a descriptor method for your own project.</p></li></ul><hr><h2 id=stage-4-energy-and-force-prediction-with-ml-models-intermediate>Stage 4: Energy and Force Prediction with ML Models (Intermediate)<a hidden class=anchor aria-hidden=true href=#stage-4-energy-and-force-prediction-with-ml-models-intermediate>#</a></h2><ul><li><p><strong>Atomic Energy Decomposition:</strong><br>Learn how total energy = sum of atomic energies in MLPs.<br><em>Goal:</em> Implement a per-atom NN model to predict total energy.</p></li><li><p><strong>Differentiation for Forces:</strong><br>Use autograd to compute forces from energy predictions.<br><em>Goal:</em> Implement a force calculation using automatic differentiation.</p></li><li><p><strong>Combined Loss Functions:</strong><br>Train models using both energy and force loss.<br><em>Goal:</em> Define a custom loss and train a model with weighted energy and force terms.</p></li><li><p><strong>Physical Constraints and Regularization:</strong><br>Apply regularization, unit conversions, and physical sanity checks.</p></li></ul><hr><h2 id=stage-5-data-generation-and-preprocessing-intermediate>Stage 5: Data Generation and Preprocessing (Intermediate)<a hidden class=anchor aria-hidden=true href=#stage-5-data-generation-and-preprocessing-intermediate>#</a></h2><ul><li><p><strong>Generating DFT Reference Data:</strong><br>Use DFT or ab initio MD to generate diverse atomic structures and outputs.<br><em>Goal:</em> Build a training dataset of structures, energies, and forces.</p></li><li><p><strong>Neighbor Lists and Cutoffs:</strong><br>Implement cutoff-based neighbor list generation.<br><em>Goal:</em> For each atom, find neighbors within a fixed radius.</p></li><li><p><strong>Feature Scaling and Formatting:</strong><br>Normalize descriptors and subtract per-atom reference energies.<br><em>Goal:</em> Prepare dataset for training.</p></li><li><p><strong>Tools:</strong><br>Use ASE, DScribe, and other utilities to automate preprocessing.<br><em>Goal:</em> Have a clean training dataset ready for ML input.</p></li></ul><hr><h2 id=stage-6-training-and-evaluating-mlps-advanced>Stage 6: Training and Evaluating MLPs (Advanced)<a hidden class=anchor aria-hidden=true href=#stage-6-training-and-evaluating-mlps-advanced>#</a></h2><ul><li><p><strong>Training Setup:</strong><br>Choose network architecture, optimizer, and loss terms.<br><em>Goal:</em> Successfully train a model on your dataset.</p></li><li><p><strong>Hyperparameter Tuning:</strong><br>Experiment with network size, learning rate, loss weights.<br><em>Goal:</em> Minimize test error and avoid overfitting.</p></li><li><p><strong>Error Evaluation:</strong><br>Use RMSE on energies and forces. Check predictions vs. DFT.<br><em>Goal:</em> Achieve meV-level errors if possible.</p></li><li><p><strong>Physical Validation:</strong><br>Run short MD or structure relaxations using your model.<br><em>Goal:</em> Confirm conservation of energy, correct equilibrium structures, etc.</p></li><li><p><strong>Active Learning (Optional):</strong><br>Expand dataset based on failure regions.<br><em>Goal:</em> Iteratively improve performance.</p></li></ul><hr><h2 id=stage-7-integration-into-simulation-frameworks-advanced>Stage 7: Integration into Simulation Frameworks (Advanced)<a hidden class=anchor aria-hidden=true href=#stage-7-integration-into-simulation-frameworks-advanced>#</a></h2><ul><li><p><strong>ASE Integration:</strong><br>Write an ASE Calculator that calls your model.<br><em>Goal:</em> Use your MLP in ASE for optimization or MD.</p></li><li><p><strong>LAMMPS Integration:</strong><br>Options include custom pair styles, Python callbacks, or external libraries.<br><em>Goal:</em> Run LAMMPS using your model (start with small test systems).</p></li><li><p><strong>OpenMM or Other Engines (Optional):</strong><br>Use with other tools like OpenMM for biomolecular systems.<br><em>Goal:</em> Connect MLP to any tool that supports custom force fields.</p></li><li><p><strong>Final Tests:</strong><br>Validate energy/force agreement between standalone and simulation engine.<br><em>Goal:</em> Use your model in real MD runs with confidence.</p></li></ul><hr><p><strong>End Goal:</strong> Be able to train your own machine learning potential on DFT data, validate its accuracy, and run real simulations (structure optimization or MD) using it in ASE or LAMMPS.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://huangchieh.github.io/>時光屋</a></span>
<span>由 <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> 和 <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a> 驅動</span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>